# Automated Resume Relevance Check System - Single File Version

import os
import docx
from pdfminer.high_level import extract_text
import pickle
import streamlit as st
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# ------------------------- Resume Parsing Functions -------------------------
def extract_text_from_pdf(pdf_path):
    return extract_text(pdf_path)

def extract_text_from_docx(docx_path):
    doc = docx.Document(docx_path)
    full_text = []
    for para in doc.paragraphs:
        full_text.append(para.text)
    return '\n'.join(full_text)

def parse_resume(file_path):
    ext = os.path.splitext(file_path)[1].lower()
    if ext == '.pdf':
        return extract_text_from_pdf(file_path)
    elif ext == '.docx':
        return extract_text_from_docx(file_path)
    else:
        raise ValueError("Unsupported file format")

def load_resumes_from_folder(folder_path):
    resumes = []
    file_names = []
    for file in os.listdir(folder_path):
        if file.endswith('.pdf') or file.endswith('.docx'):
            text = parse_resume(os.path.join(folder_path, file))
            resumes.append(text)
            file_names.append(file)
    return resumes, file_names

# ------------------------- Job Matching Functions -------------------------
def train_vectorizer(sample_texts):
    vectorizer = TfidfVectorizer(stop_words='english')
    vectorizer.fit(sample_texts)
    os.makedirs('models', exist_ok=True)
    with open('models/skill_vectorizer.pkl', 'wb') as f:
        pickle.dump(vectorizer, f)
    return vectorizer

def load_vectorizer():
    with open('models/skill_vectorizer.pkl', 'rb') as f:
        return pickle.load(f)

def compute_similarity(resume_text, job_text, vectorizer):
    vectors = vectorizer.transform([resume_text, job_text])
    similarity = cosine_similarity(vectors[0], vectors[1])[0][0]
    return similarity

def rank_resumes(resumes_texts, job_text):
    vectorizer = load_vectorizer()
    scores = []
    for r in resumes_texts:
        score = compute_similarity(r, job_text, vectorizer)
        scores.append(score)
    return scores

# ------------------------- Streamlit Web App -------------------------
st.title("Automated Resume Relevance Check System")

# Upload resumes folder
resumes_folder = st.text_input("Enter resumes folder path", "data/sample_resumes")
resumes, filenames = load_resumes_from_folder(resumes_folder)

# Upload job description
job_file = st.file_uploader("Upload Job Description (.txt)", type=['txt'])

if job_file:
    job_text = job_file.read().decode("utf-8")

    # Train vectorizer on resumes + job description
    train_vectorizer(resumes + [job_text])

    # Rank resumes
    scores = rank_resumes(resumes, job_text)

    # Display results
    ranked = sorted(zip(filenames, scores), key=lambda x: x[1], reverse=True)
    st.subheader("Ranked Resumes")
    for fname, score in ranked:
        st.write(f"{fname} - Relevance Score: {score:.2f}")

# ------------------------- Sample Data Instructions -------------------------
st.markdown("### Sample Data:")
st.markdown("Place your resumes in `data/sample_resumes/` as PDF or DOCX files.")
st.markdown("Upload a job description as a `.txt` file to test the system.")
